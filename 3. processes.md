# более общее, затрагивающее любые источники
## процессы (IDEF0 был бы более наглядным, но съест очень много времени)
0) анализ источника (приоритет, надо ли вообще); 
1) поиск информации по существующим источнику, документации, CVE; 
    + для поиска информации необходимо понимание какие базы используются, есть ли автоматизация, в каком виде она выдает информацию.   
    если автоматизации по разным базам нет, но уязвимость важная, то пройтись по всем существующим базам, разложить ее и осознать  
    в идеальном мире скрипты должны приносить только трендовые уязвимости, с сылкой на эксплойт, с указанием как часто используется ПО и т.д.
3) стендирование; 
    для стендирования нужно понимать используется ли автоматизация развертывания, используется ли большой лабороторный полигон и какие там правила вставки, с кем обсуждать, кто выделит сетевую адресацию.  
    в идеальном мире, должна быть тестовая инфраструктура, где уже есть домены, какая-то имитация жизнедеятельности, хосты разворачиваются указанием основных параметров, а также ОС, которая нужна, в процессе настройки эксперт описывает команды необходимые для установки, чтобы в будущем стенд можно было развернуть "одним нажатием" (для обновления данных по экспертизе). тогда и процесс будет в инструкции: как запустить развертывание и в каком формате сохранять команды необходмые для установки
2) написание ТЗ на автоматизацию поиска CVE для данного продукта; 
    + сайт вендора, как именно он отмечает свои уязвимости, как у него устроена нумерация? завязана ли она на mitre? формат представления патч-ноутс с закрытием уязвимостий, формат представления бюллетеней. 
    + есть ли каналы, которые специализируются на данном ПО, например сайты коммьюнити, где могут в прямом виде спрашивать когда и как закрыть определенную уязвимость
4) анализ конфигов и иных источников данных для модели; 
    + возможности по настройке, можно ли вообще харденить или максимальные конфигурирование источника - управления пользователями?
    + можно ли заполнять модель из событий? каких? где их включить и как собрать?
5) составление модели;  
    нужно понимание внутренней структуры модели и насколько она расширяема.  
6) написание ТЗ на аудит:   
    имея описание как праивльно формировать ТЗ, единый стандартый вид, постепенно наполняя его
    + краткое описание зачем
    + права доступа
    + команды в обговоренном виде (то есть дополнение команды, чтобы она доставала только нужные данные или описание как получить их (awk/grep/find) + сама команда)
    + указание в какое поле модели необходимо занести данные
    + может ли быть пустым, что делать в этом случае
    + какие могут быть ошибки (нехватка прав, отсутствие файла и т.д.) 
7) составление ТЗ на ПенТест (сбор скриптов, составление новых);  
    имея описание как праивльно формировать ТЗ, единый стандартый вид, постепенно наполняя его
    + краткое описание зачем
    + права доступа
    + команды в обговоренном виде
    + обработка выходных значений, какие данные свидетельствуют об успехе, какие о провале.
8) ревью ТЗ и модели
    + другими коллегами
    + разработчиками
8) ревью скриптов по ТЗ
    + разработчиками
    + автором ТЗ
9) ручное тестирование скриптов
    + на исходном стенде
    + после сброса к нулевому состоянию
    + после харденинга
10) автоматизация тестирования
    в идеальном мире: 
    + CI/CD по кусочкам (unit-тестирование), там где это возможно
    + раз в иногда:
        - автоматическое стендирование
        - автоматический запуск скриптов
        - валидация выходных параметров и времени выполнения (поиск деградаций)
11) поддержка по выходу новых версий, багов или новых важных CVE (возвращение на 1, но не с нуля)
 
 
### организационные вопросы 
* взаимодействие команд, в том числе неформальное, никто из команд не должен принижать заслуги другой команды, если есть возможность проведения совместных межкомандых мероприятий, которые покажут что в другом отделе тоже люди, неглупые люди, то это положительно скажется на итоговый продукт. 
* проработанный формат заведения задач*
* понимание стека технологий и возможностей команд. Общее представление кто в каком отделе хорош в каком направлении, касательно экспертов: какие ТЗ до этого писал, что было интересного в каждом, касательно разработки: ЯП под капотом, какие скрипты писал, какие ТЗ понравились, какие вызывают душевную боль до сих пор.
* а также обмен новыми знаниями, то есть если в сканнере происходят важные изменения, добавляется метод подключения или часть функций уходит в общие шаблонные функции, то это полезная информация, которую следует подсвечивать между командами, хотя бы короткими 15-минутными встречами раз в неделю, кому будет интересно сами придут за подробностями.
* доступ к трекеру и понимание загрузки команд (для руководителей, чтобы как-то распредлить нагрузку)
* умение вставлять в план задачи для минимально возможных швов между командами. Если в эксперта летит задача, которая точно перейдет в разработку, то задачу на разработку можно заводить сразу, ставя старт_тайм как время выполнение экспертной составляющей + 2 недели (форс-мажоры). это позволит минимизировать потери знаний эксперта и ускорит общее время выполнение. 
* оценка и минимизация задач пролетающих мимо стандартного пайплайна (сверху) (от этого никуда не деться, но постоянное смещение низкоуровневой фичи может привести к печальным последствиям) 

[*] что имеет ввиду под проработка формата задач и вообще вводных данных:  
все пункты работы с Checkbox-ами, отдельные поля под заполняемые данные  
Проще на примере организации деятельности по поддержкам сиема в ютреке (который на мой взгляд безумно гибкий):
1) для начала была собрана вся возможная внутренняя документация, вебинары, хорошие статьи
2) собраны источники по атакам, тот же exploit-db, hacktrix и т.д.
3) декомпозирован черный ящик поддержки по винтикам, вплоть до ТЗ надо писать сначала шапка - вот эта, таблица - вот эта и т.д. (именно с учетом существующих или обоговариваемых с разработкой условий)
4) потом из пуктов начали вырезаться избыточные шаги, итеративно, обсуждая с администраторами проектов, а также с людьми, которые не знакомы с поддержками
5) добавлены поля, куда при выполнение задачи необходимо было добавлять информацию, например: ссылки на ТЗ, расположение и креды стенда.
5) добавлены пункты про заполнение полей. Если есть поле "описание стенда" и есть пункт развертывание стенда, то следующий пункт после него "в поле описание стенда приложено расположение стенда и креды для доступа"
6) в пункт про заведение задачи на смежный отдел добавлялся шаблон заведения (автоматический) задачи, с автоматическим выставлением всех полей, которые можно заранее заполнить из главной задачи. 
то есть обобщая: создавая шаблон я пытался заранее описать все процессы, где могли бы возникнуть вопросы и автоматизацией минимизировать типовые операции, чтобы работа эксперта была исключительно в экспертизе (*и проставлении галочек).  

 
## человеко-ресурсы и временные рамки 
1) эксперт 1 месяц - минимальная работа то есть VM, минимальная модель (версия и где ее взять), либо 2 месяца (+ТЗ атак, модель достаточная для комплаенса) 
2) разработчик 2 недели - реализация всех ТЗ и тестирование, если с атаками, то еще 1-2 недели. 

максимальное время от взяли в работу → появилось в продукте: 4 месяца 
 
 
## Риски 
* отсутствие документации на конфигурирование, может увеличить срок реализации; 
* нераспространенность ПО и как следствие малая известность атак и уязвимостей, которые могут найтись в процессе, может оказаться что ВМ будет бесполезен и не отображать реальную уязвимость ПО и инфраструктуры; 
* отсутствие методов подключения сканнера, если придется добавлять фундаментальный функционал в сканнер, то срок его реализации вырастет; 
* плохие договоренности между командами, если эксперт не будет ревьювить своевременно разработчик может переключиться на другую задачу и получится бесконечное ожидание друг друга, что увеличит сроки. 
 